{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0c32bf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T12:12:53.492761Z",
     "start_time": "2023-06-19T12:12:50.548767Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\sata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import contractions\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bdc56aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T12:12:53.620729Z",
     "start_time": "2023-06-19T12:12:53.494734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_created</th>\n",
       "      <th>post_text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>followers</th>\n",
       "      <th>friends</th>\n",
       "      <th>favourites</th>\n",
       "      <th>statuses</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6.380000e+17</td>\n",
       "      <td>Sun Aug 30 07:48:37 +0000 2015</td>\n",
       "      <td>It's just over 2 years since I was diagnosed w...</td>\n",
       "      <td>1.013187e+09</td>\n",
       "      <td>84</td>\n",
       "      <td>211</td>\n",
       "      <td>251</td>\n",
       "      <td>837</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.380000e+17</td>\n",
       "      <td>Sun Aug 30 07:31:33 +0000 2015</td>\n",
       "      <td>It's Sunday, I need a break, so I'm planning t...</td>\n",
       "      <td>1.013187e+09</td>\n",
       "      <td>84</td>\n",
       "      <td>211</td>\n",
       "      <td>251</td>\n",
       "      <td>837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6.380000e+17</td>\n",
       "      <td>Sat Aug 29 22:11:07 +0000 2015</td>\n",
       "      <td>Awake but tired. I need to sleep but my brain ...</td>\n",
       "      <td>1.013187e+09</td>\n",
       "      <td>84</td>\n",
       "      <td>211</td>\n",
       "      <td>251</td>\n",
       "      <td>837</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6.380000e+17</td>\n",
       "      <td>Sat Aug 29 18:40:49 +0000 2015</td>\n",
       "      <td>RT @SewHQ: #Retro bears make perfect gifts and...</td>\n",
       "      <td>1.013187e+09</td>\n",
       "      <td>84</td>\n",
       "      <td>211</td>\n",
       "      <td>251</td>\n",
       "      <td>837</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6.380000e+17</td>\n",
       "      <td>Sat Aug 29 18:40:26 +0000 2015</td>\n",
       "      <td>It’s hard to say whether packing lists are mak...</td>\n",
       "      <td>1.013187e+09</td>\n",
       "      <td>84</td>\n",
       "      <td>211</td>\n",
       "      <td>251</td>\n",
       "      <td>837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>19995</td>\n",
       "      <td>8.190000e+17</td>\n",
       "      <td>Thu Jan 12 00:14:56 +0000 2017</td>\n",
       "      <td>A day without sunshine is like night.</td>\n",
       "      <td>1.169876e+09</td>\n",
       "      <td>442</td>\n",
       "      <td>230</td>\n",
       "      <td>7</td>\n",
       "      <td>1063601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>19996</td>\n",
       "      <td>8.190000e+17</td>\n",
       "      <td>Thu Jan 12 00:06:18 +0000 2017</td>\n",
       "      <td>Boren's Laws: (1) When in charge, ponder. (2) ...</td>\n",
       "      <td>1.169876e+09</td>\n",
       "      <td>442</td>\n",
       "      <td>230</td>\n",
       "      <td>7</td>\n",
       "      <td>1063601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>19997</td>\n",
       "      <td>8.190000e+17</td>\n",
       "      <td>Thu Jan 12 00:05:42 +0000 2017</td>\n",
       "      <td>The flow chart is a most thoroughly oversold p...</td>\n",
       "      <td>1.169876e+09</td>\n",
       "      <td>442</td>\n",
       "      <td>230</td>\n",
       "      <td>7</td>\n",
       "      <td>1063601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>19998</td>\n",
       "      <td>8.190000e+17</td>\n",
       "      <td>Thu Jan 12 00:05:22 +0000 2017</td>\n",
       "      <td>Ships are safe in harbor, but they were never ...</td>\n",
       "      <td>1.169876e+09</td>\n",
       "      <td>442</td>\n",
       "      <td>230</td>\n",
       "      <td>7</td>\n",
       "      <td>1063601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>19999</td>\n",
       "      <td>8.190000e+17</td>\n",
       "      <td>Thu Jan 12 00:04:47 +0000 2017</td>\n",
       "      <td>Black holes are where God is dividing by zero.</td>\n",
       "      <td>1.169876e+09</td>\n",
       "      <td>442</td>\n",
       "      <td>230</td>\n",
       "      <td>7</td>\n",
       "      <td>1063601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       post_id                    post_created  \\\n",
       "0               0  6.380000e+17  Sun Aug 30 07:48:37 +0000 2015   \n",
       "1               1  6.380000e+17  Sun Aug 30 07:31:33 +0000 2015   \n",
       "2               2  6.380000e+17  Sat Aug 29 22:11:07 +0000 2015   \n",
       "3               3  6.380000e+17  Sat Aug 29 18:40:49 +0000 2015   \n",
       "4               4  6.380000e+17  Sat Aug 29 18:40:26 +0000 2015   \n",
       "...           ...           ...                             ...   \n",
       "19995       19995  8.190000e+17  Thu Jan 12 00:14:56 +0000 2017   \n",
       "19996       19996  8.190000e+17  Thu Jan 12 00:06:18 +0000 2017   \n",
       "19997       19997  8.190000e+17  Thu Jan 12 00:05:42 +0000 2017   \n",
       "19998       19998  8.190000e+17  Thu Jan 12 00:05:22 +0000 2017   \n",
       "19999       19999  8.190000e+17  Thu Jan 12 00:04:47 +0000 2017   \n",
       "\n",
       "                                               post_text       user_id  \\\n",
       "0      It's just over 2 years since I was diagnosed w...  1.013187e+09   \n",
       "1      It's Sunday, I need a break, so I'm planning t...  1.013187e+09   \n",
       "2      Awake but tired. I need to sleep but my brain ...  1.013187e+09   \n",
       "3      RT @SewHQ: #Retro bears make perfect gifts and...  1.013187e+09   \n",
       "4      It’s hard to say whether packing lists are mak...  1.013187e+09   \n",
       "...                                                  ...           ...   \n",
       "19995              A day without sunshine is like night.  1.169876e+09   \n",
       "19996  Boren's Laws: (1) When in charge, ponder. (2) ...  1.169876e+09   \n",
       "19997  The flow chart is a most thoroughly oversold p...  1.169876e+09   \n",
       "19998  Ships are safe in harbor, but they were never ...  1.169876e+09   \n",
       "19999     Black holes are where God is dividing by zero.  1.169876e+09   \n",
       "\n",
       "       followers  friends  favourites  statuses  retweets  \n",
       "0             84      211         251       837         0  \n",
       "1             84      211         251       837         1  \n",
       "2             84      211         251       837         0  \n",
       "3             84      211         251       837         2  \n",
       "4             84      211         251       837         1  \n",
       "...          ...      ...         ...       ...       ...  \n",
       "19995        442      230           7   1063601         0  \n",
       "19996        442      230           7   1063601         0  \n",
       "19997        442      230           7   1063601         0  \n",
       "19998        442      230           7   1063601         0  \n",
       "19999        442      230           7   1063601         0  \n",
       "\n",
       "[20000 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Mental-Health-Twitterr.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "543baf64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T12:12:53.636729Z",
     "start_time": "2023-06-19T12:12:53.621725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    It's just over 2 years since I was diagnosed w...\n",
       "1    It's Sunday, I need a break, so I'm planning t...\n",
       "2    Awake but tired. I need to sleep but my brain ...\n",
       "3    RT @SewHQ: #Retro bears make perfect gifts and...\n",
       "4    It’s hard to say whether packing lists are mak...\n",
       "Name: post_text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[\"post_text\"]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb884056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T12:12:53.652767Z",
     "start_time": "2023-06-19T12:12:53.639730Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2762c9a8",
   "metadata": {},
   "source": [
    "# Text preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "620b29c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T12:12:53.953723Z",
     "start_time": "2023-06-19T12:12:53.654730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    it is just over  years since i was diagnosed w...\n",
       "1    it is sunday i need a break so i am planning t...\n",
       "2    awake but tired i need to sleep but my brain h...\n",
       "3    rt sewhq retro bears make perfect gifts and ar...\n",
       "4    it is hard to say whether packing lists are ma...\n",
       "Name: post_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tweets characters to lowercase\n",
    "df = df.str.lower()\n",
    "#expands shortened words\n",
    "df = df.apply(lambda x: contractions.fix(x))\n",
    "\n",
    "# Remove numbers from tweets as they do not indicate anything\n",
    "df = df.str.replace('\\d+', '', regex=True)\n",
    "\n",
    "# Remove punctuation from tweets\n",
    "df = df.str.replace(\"[^\\w\\s]\", \"\", regex=True)\n",
    "\n",
    "# Remove URLs from tweets\n",
    "df = df.str.replace(r\"http\\S+|www\\S+|https\\S+\", \"\", regex=True)\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b503557",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T12:13:02.031729Z",
     "start_time": "2023-06-19T12:12:53.956730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [year, since, diagnosed, anxiety, depression, ...\n",
       "1    [sunday, need, break, planning, spend, little,...\n",
       "2             [awake, tired, need, sleep, brain, idea]\n",
       "3    [rt, sewhq, retro, bear, make, perfect, gift, ...\n",
       "4    [hard, say, whether, packing, list, making, li...\n",
       "Name: post_text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords_and_lemmatize(tweets):\n",
    "    filtered_tokens = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(tweets)\n",
    "    for tweet in tokens:\n",
    "        if tweet not in stop_words:\n",
    "            lemmatized_word = lemmatizer.lemmatize(tweet)\n",
    "            filtered_tokens.append(lemmatized_word)\n",
    "#     filtered_text = ' '.join(filtered_tokens)\n",
    "#     Return the filtered text\n",
    "    return filtered_tokens\n",
    "        \n",
    "df=df.apply(remove_stopwords_and_lemmatize)    \n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4075795",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-19T12:12:50.555Z"
    }
   },
   "outputs": [],
   "source": [
    "def correct_spelling(word_list):\n",
    "    spell = SpellChecker()\n",
    "    corrected_list = []\n",
    "    for word in word_list:\n",
    "        corrected_word = spell.correction(word)\n",
    "        corrected_list.append(corrected_word)\n",
    "    return corrected_list\n",
    "\n",
    "df=df.apply(correct_spelling)    \n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0429031e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T19:42:01.473828Z",
     "start_time": "2023-06-15T19:42:01.455866Z"
    }
   },
   "source": [
    "# Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8527eedc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1bba8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-19T12:12:50.558Z"
    }
   },
   "outputs": [],
   "source": [
    "#classify the tweets based on it's polarity to depressed'1' or not '0' \n",
    "def classify_sentiment(word_list):\n",
    "    polarity = 0\n",
    "    text = ' '.join(str(word) for word in word_list)  # Join the list of words into a single string\n",
    "    blob = TextBlob(text)\n",
    "    polarity += blob.sentiment.polarity\n",
    "    if polarity > .1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "# Apply sentiment classification to the 'text' column in the DataFrame\n",
    "df['sentiment']=df['post_text'].apply(classify_sentiment)\n",
    "labels=df['sentiment'].value_counts()\n",
    "labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed9c53a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-19T12:12:50.559Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "# Assign the categorical labels directly\n",
    "labels.index = ['Depressed', ' Not Depressed']\n",
    "\n",
    "# Create the bar plot\n",
    "labels.plot(kind=\"bar\", rot=0, color=[\"plum\", \"cyan\"])\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel(\"Tweets\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b5503a",
   "metadata": {},
   "source": [
    "# splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5551f7b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-19T12:12:50.561Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['post_text'], df['sentiment'], test_size=0.25, random_state=42)\n",
    "X_train = [' '.join(filter(None, doc)) for doc in X_train]\n",
    "X_test = [' '.join(filter(None, doc)) for doc in X_test]\n",
    "\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23b7914",
   "metadata": {},
   "source": [
    " # Convert the text data into numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852ae3ee",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-19T12:12:50.563Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd289d2",
   "metadata": {},
   "source": [
    "# Train model (naive bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292b9c81",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-19T12:12:50.564Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "sample_texts = [' not depressed', 'depressed',]\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "# Create a list to store qualitative predictions\n",
    "qualitative_predictions = []\n",
    "\n",
    "# Map predicted labels to qualitative interpretations\n",
    "for pred in y_pred:\n",
    "    if pred == 0:\n",
    "        qualitative_predictions.append('normal')\n",
    "\n",
    "    else :\n",
    "        qualitative_predictions.append('depressed')\n",
    "\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "#print results of random 10 test data\n",
    "print(\"quantative_predictions :\",y_pred[10:20])\n",
    "print(\"qualitative_predictions :\",qualitative_predictions[10:20])\n",
    "\n",
    "# Plotting the quantitative results\n",
    "normal_count = np.count_nonzero(y_pred == 0)\n",
    "depressed_count = np.count_nonzero(y_pred == 1)\n",
    "labels = ['Normal', 'Depressed']\n",
    "\n",
    "counts = [normal_count, depressed_count]\n",
    "\n",
    "plt.bar(labels, counts)\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Prediction Results')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0852363",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-19T12:12:50.566Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, nb.predict(X_test))\n",
    "cm = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=nb.classes_)\n",
    "cm.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e19318",
   "metadata": {},
   "source": [
    "# trying random sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03321f0e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-19T12:12:50.568Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred = nb.predict(vectorizer.transform([' love  to hate myself']))\n",
    "print(\"depressed\",y_pred)\n",
    "y_pred = nb.predict(vectorizer.transform([' love  myself']))\n",
    "print(\"Normal\",y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e483ba07",
   "metadata": {},
   "source": [
    "# random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3d2b29",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-19T12:12:50.569Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "accuracy = rf.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a3e3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
